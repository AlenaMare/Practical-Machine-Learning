---
title: "Course Project_Practical Machine Learning"
author: "AM"
date: "25 11 2022"
output:
  md_document:
    df_print: paged
---

## Overview

One thing that people regularly do is quantify how  much of a particular activity they do, but they rarely quantify how well they do it. 

In this project, I will use data from accelerators on the belt, forearm, arm, and dumbbell of 6 participants. The goal of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. Report describes building of a model, using of a cross validation, what I expect out of sample error to be.

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

## Data Processing

```{r setup}
library(caret)
library(randomForest)
library(corrplot)
library(rpart)
```

## Data Processing


```{r, echo=TRUE}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile, method="curl")
}
```

## Read the Data

```{r, echo=TRUE}
trainRaw <- read.csv("./data/pml-training.csv")
testRaw <- read.csv("./data/pml-testing.csv")
dim(trainRaw)
dim(testRaw)
```

The training data set contains 19622 observations and 160 variables, while the testing data set contains 20 observations and 160 variables. The "classe" variable in the training set is the outcome to predict.

## Clean the data

First, we remove columns that contain NA missing values.

```{r, echo=TRUE}
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) < .9] 
trainRaw <- trainRaw[,-c(1:7)]
```
Removing near zero variance variables.

```{r, echo=TRUE}
nvz <- nearZeroVar(trainRaw)
trainRaw <- trainRaw[,-nvz]
dim(trainRaw)
```

Now, the cleaned training data set contains 19622 observations and 53 variables.

Next, we can split the cleaned training set into into a pure training data set (70%) and a validation data set (30%). We will use the validation data set to conduct cross validation in future steps.

```{r, echo=TRUE}
inTrain <- createDataPartition(y=trainRaw$classe, p=0.7, list=F)
train <- trainRaw[inTrain,]
valid <- trainRaw[-inTrain,]
```

## Data Modeling

We fit two models, namely Random Forest and Support Vector Machine. First, I set up control for training to use threefold cross validation, than the valid set.

# Random Forest
```{r, echo=TRUE}
controlRf <- trainControl(method="cv", 5)
mod_rf <- train(classe~., data=train, method="rf", trControl = controlRf, tuneLength = 5)
mod_rf
```

```{r, echo=TRUE}
pred_rf <- predict(mod_rf, valid)
confusionMatrix(pred_rf, factor(valid$classe))
```
# Support Vector Machine
```{r, echo=TRUE}
mod_svm <- train(classe~., data=train, method="svmLinear", trControl = controlRf, tuneLength = 5, verbose = F)
mod_svm
```

```{r, echo=TRUE}
pred_svm <- predict(mod_svm, valid)
confusionMatrix(pred_svm, factor(valid$classe))
```

The better model is Random Forest model, with accuracy .9958 compared to Support Vector Machine Model, with accuracy 0.7832. 

## Predicting for Test Data Set

Now, we apply the model to the original testing data set downloaded from the data source. 

```{r, echo=TRUE}
result <- predict(mod_rf, testRaw)
print(result)
```
## Appendix: Figures

Correlation Matrix Visualization

```{r, echo=TRUE}
corrPlot <- cor(trainRaw[, -length(names(trainRaw))])
corrplot(corrPlot, method="color")
```
Plotting the models - Random Forest
```{r, echo=TRUE}
plot(mod_rf)
```
